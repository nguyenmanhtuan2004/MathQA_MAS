{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a479ed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from mint.config import DATA_DIR\n",
    "import os\n",
    "import json\n",
    "from pydantic import BaseModel,Field\n",
    "from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import textwrap\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Optional\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import traceback\n",
    "from langsmith import Client, traceable, evaluate\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Optional\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from langsmith import traceable, trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf710b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "data_dir = DATA_DIR(\"GSM8K\")\n",
    "\n",
    "dataset = load_jsonl(os.path.join(data_dir, 'test.jsonl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5890371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "model = init_chat_model(\"gpt-4.1-mini\", model_provider=\"openai\", temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b39465d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    program: Optional[str]\n",
    "    result: Optional[str]\n",
    "    final_answer: Optional[str]\n",
    "    error: Optional[str]\n",
    "class IntermediateProgram(BaseModel):\n",
    "    program: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5a9b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(run_type=\"prompt\")\n",
    "def pot_node(state: State) -> State:\n",
    "    pot_messages = [\n",
    "        SystemMessage(\"\"\"\n",
    "# Answer this question by implementing a solver() function.\n",
    "# Write a Python program, and then return the answer.\n",
    "Question: Carlos is planing a lemon tree. The tree will cost $90 to plant. Each year it will grow 7 lemons, which he\n",
    "can sell for $1.5 each. It costs $3 a year to water and feed the tree. How many years will it take before he starts earning money on the lemon tree?\n",
    "def solver():\n",
    "    total_cost = 90\n",
    "    cost_of_watering_and_feeding = 3\n",
    "    cost_of_each_lemon = 1.5\n",
    "    num_of_lemon_per_year = 7\n",
    "    ans = 0\n",
    "    while total_cost > 0:\n",
    "        total_cost += cost_of_watering_and_feeding\n",
    "        total_cost -= num_of_lemon_per_year * cost_of_each_lemon\n",
    "        ans += 1\n",
    "    return ans\n",
    "Question: When Freda cooks canned tomatoes into sauce, they lose half their volume. Each 16 ounce can of\n",
    "tomatoes that she uses contains three tomatoes. Freda’s last batch of tomato sauce made 32 ounces of sauce. How\n",
    "many tomatoes did Freda use?\n",
    "def solver():\n",
    "    lose_rate = 0.5\n",
    "    num_tomato_contained_in_per_ounce_sauce = 3 / 16\n",
    "    ounce_sauce_in_last_batch = 32\n",
    "    num_tomato_in_last_batch = ounce_sauce_in_last_batch * num_tomato_contained_in_per_ounce_sauce\n",
    "    ans = num_tomato_in_last_batch / (1 - lose_rate)\n",
    "    return ans\n",
    "    \n",
    "Question: Jordan wanted to surprise her mom with a homemade birthday cake. From reading the instructions, she\n",
    "knew it would take 20 minutes to make the cake bajer and 30 minutes to bake the cake. The cake would require 2\n",
    "hours to cool and an additional 10 minutes to frost the cake. If she plans to make the cake all on the sam\n",
    "def solver():\n",
    "    minutes_to_make_bajer = 20\n",
    "    minutes_to_bake_cake = 30\n",
    "    minutes_to_cool_cake = 2 * 60\n",
    "    minutes_to_frost_cake = 10\n",
    "    total_minutes = minutes_to_make_bajer + minutes_to_bake_cake + minutes_to_cool_cake +\n",
    "    minutes_to_frost_cake\n",
    "    total_hours = total_minutes / 60\n",
    "    ans = 5 - total_hours\n",
    "    return ans\n",
    "\"\"\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "# Question: {state[\"question\"]}\n",
    "# If the final result is a decimal ending in .0, convert it to an integer before returning.\n",
    "# Call the solver function and 'MUST' assign the variale 'result'.\n",
    "# Before returning the final result, DOUBLE-CHECK each variable assignment and calculation to ensure they match the problem statement.\n",
    "\"\"\")]\n",
    "\n",
    "    model_pot = model.with_structured_output(IntermediateProgram)\n",
    "    model_invoke=model_pot.invoke(pot_messages)\n",
    "    code=model_invoke.program\n",
    "    return {**state, \"program\": code}\n",
    "    \n",
    "@traceable(run_type=\"parser\")\n",
    "def exec_node(state: State) -> State:\n",
    "    try:\n",
    "        exec_globals = {}\n",
    "        exec(state[\"program\"], {}, exec_globals)\n",
    "        result = exec_globals.get(\"result\", None)\n",
    "        if result is None:\n",
    "            raise ValueError(\"Missing `result`\")\n",
    "        return {**state, \"result\": str(result), \"error\": None}\n",
    "    except Exception as e:\n",
    "        return {**state, \"result\": None, \"error\": str(e)}\n",
    "\n",
    "def check_eos(state: State) -> bool:\n",
    "    if state[\"error\"] is None:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def write_final_answer_node(state:State)->State:\n",
    "\n",
    "    if state[\"error\"] is None:\n",
    "        result=str(state[\"result\"])\n",
    "    else:\n",
    "        result=str(9999)\n",
    "    return {**state,\"final_answer\":result}\n",
    "\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"PoT\", pot_node)\n",
    "builder.add_node(\"Exec\", exec_node)\n",
    "\n",
    "builder.add_node(\"write_final_answer\",write_final_answer_node)\n",
    "\n",
    "builder.set_entry_point(\"PoT\")\n",
    "builder.add_edge(\"PoT\", \"Exec\")\n",
    "builder.add_edge(\"Exec\", \"write_final_answer\")\n",
    "builder.add_edge(\"write_final_answer\",END)\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c476265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(run_type=\"tool\")\n",
    "def extract_ground_truth(answer: str) -> str:\n",
    "    match = re.search(r\"####\\s*([\\d,]+)\", answer)\n",
    "    if match:\n",
    "        # Loại bỏ dấu phẩy để đảm bảo kết quả là số chuẩn\n",
    "        return match.group(1).replace(\",\", \"\").strip()\n",
    "    return \"\"\n",
    "\n",
    "@traceable(run_type=\"tool\")\n",
    "def compare_answers(predicted: str, actual: str, eps: float = 1e-3) -> bool:\n",
    "    try:\n",
    "        pred = round(float(predicted.strip()))\n",
    "        act = round(float(actual.strip()))\n",
    "        return abs(pred - act) < eps\n",
    "    except ValueError:\n",
    "        return predicted.strip().lower() == actual.strip().lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87bda2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:11<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00% (10/10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "@traceable(run_type=\"chain\")\n",
    "def process_item(item):\n",
    "    question = item[\"question\"]\n",
    "    true_answer = extract_ground_truth(item[\"answer\"])\n",
    "    try:\n",
    "        result = graph.invoke({\"question\": question})\n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"program\":result[\"program\"],\n",
    "            \"true_answer\": true_answer,\n",
    "            \"predicted_answer\": result[\"final_answer\"],\n",
    "            \"correct\": compare_answers(result[\"final_answer\"], true_answer)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"question\": question}\n",
    "\n",
    "results = []\n",
    "correct = 0\n",
    "total = len(dataset[:10])\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = [executor.submit(process_item, item) for item in dataset[:10]]\n",
    "    for future in tqdm(as_completed(futures), total=total):\n",
    "        result = future.result()\n",
    "        if \"error\" not in result:\n",
    "            results.append(result)\n",
    "            if result[\"correct\"]:\n",
    "                correct += 1\n",
    "        else:\n",
    "            print(f\"Error on question: {result['question'][:60]}... => {result['error']}\")\n",
    "accuracy = correct / total * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}% ({correct}/{total})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "776be706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu kết quả vào PoT_results.json\n"
     ]
    }
   ],
   "source": [
    "output_path = \"PoT_results.json\"\n",
    "wrong_answers = [r for r in results if not r[\"correct\"]]\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(wrong_answers, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "print(f\"Đã lưu kết quả vào {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9b2ff7-54e6-4000-83a3-45bbb193a415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
